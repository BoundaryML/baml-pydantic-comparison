# This file is generated by the BAML compiler.
# Do not edit this file directly.
# Instead, edit the BAML files and recompile.

# ruff: noqa: E501,F401
# flake8: noqa: E501,F401
# pylint: disable=unused-import,line-too-long
# fmt: off

from ..clients.client_gpt4 import GPT4
from ..functions.fx_analyzerestorationproject import BAMLAnalyzeRestorationProject
from ..types.classes.cls_complexrestorationproject import ComplexRestorationProject
from ..types.classes.cls_manuscriptcondition import ManuscriptCondition
from ..types.classes.cls_manuscriptcontext import ManuscriptContext
from ..types.classes.cls_restoration import Restoration
from ..types.enums.enm_manuscriptstate import ManuscriptState
from ..types.enums.enm_materialorigin import MaterialOrigin
from ..types.enums.enm_timeperiod import TimePeriod
from ..types.partial.classes.cls_complexrestorationproject import PartialComplexRestorationProject
from ..types.partial.classes.cls_manuscriptcondition import PartialManuscriptCondition
from ..types.partial.classes.cls_manuscriptcontext import PartialManuscriptContext
from ..types.partial.classes.cls_restoration import PartialRestoration
from baml_core.provider_manager.llm_response import LLMResponse
from baml_core.stream import AsyncStream
from baml_lib._impl.deserializer import Deserializer


import typing
# Impl: v1
# Client: GPT4
# An implementation of AnalyzeRestorationProject.

__prompt_template = """\
Given the following restoration project document, analyze the details and provide the following information in json schema format:

Document:
---
{arg}
---


Use these enum definitions:
TimePeriod
---
ANCIENT
MEDIEVAL
RENAISSANCE
MODERN
---

MaterialOrigin
---
NATURAL
SYNTHETIC
---

ManuscriptState
---
INITIAL
RESTORED
---

Answer in this JSON format:
{
  "id": string,
  "title": string,
  "context": {
    "timePeriod": "TimePeriod as string",
    "origin": string | null,
    "importance": string | null
  },
  "materials": {
    "baseMaterials": "MaterialOrigin as string"[],
    "inkAndBindMaterials": string[],
    "additionalTechniques": string[]
  },
  "condition": {
    "initialState": "ManuscriptState as string",
    "finalState": "ManuscriptState as string",
    "actionsTaken": string[],
    "unresolvedIssues": string[]
  },
  "actionsTaken": string[],
  "unresolvedIssues": string[],
  "isComplete": bool
}

JSON:\
"""

__input_replacers = {
    "{arg}"
}


# We ignore the type here because baml does some type magic to make this work
# for inline SpecialForms like Optional, Union, List.
__deserializer = Deserializer[ComplexRestorationProject](ComplexRestorationProject)  # type: ignore

# Add a deserializer that handles stream responses, which are all Partial types
__partial_deserializer = Deserializer[PartialComplexRestorationProject](PartialComplexRestorationProject)  # type: ignore







async def v1(arg: str, /) -> ComplexRestorationProject:
    response = await GPT4.run_prompt_template(template=__prompt_template, replacers=__input_replacers, params=dict(arg=arg))
    deserialized = __deserializer.from_string(response.generated)
    return deserialized


def v1_stream(arg: str, /) -> AsyncStream[ComplexRestorationProject, PartialComplexRestorationProject]:
    def run_prompt() -> typing.AsyncIterator[LLMResponse]:
        raw_stream = GPT4.run_prompt_template_stream(template=__prompt_template, replacers=__input_replacers, params=dict(arg=arg))
        return raw_stream
    stream = AsyncStream(stream_cb=run_prompt, partial_deserializer=__partial_deserializer, final_deserializer=__deserializer)
    return stream

BAMLAnalyzeRestorationProject.register_impl("v1")(v1, v1_stream)